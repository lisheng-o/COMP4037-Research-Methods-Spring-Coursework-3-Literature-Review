@article{10.1145/3571730,
    author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
    title = {Survey of Hallucination in Natural Language Generation},
    year = {2023},
    issue_date = {December 2023},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {55},
    number = {12},
    issn = {0360-0300},
    url = {https://doi.org/10.1145/3571730},
    doi = {10.1145/3571730},
    abstract = {Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation, and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before.In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions, and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.},
    journal = {ACM Comput. Surv.},
    month = mar,
    articleno = {248},
    numpages = {38},
    keywords = {consistency in NLG, factuality in NLG, faithfulness in NLG, extrinsic hallucination, intrinsic hallucination, Hallucination}
}
@inproceedings{10.5555/3495724.3496517,
    author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K\"{u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt\"{a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
    title = {Retrieval-augmented generation for knowledge-intensive NLP tasks},
    year = {2020},
    isbn = {9781713829546},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) — models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, and another which can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state of the art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
    booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
    articleno = {793},
    numpages = {16},
    location = {Vancouver, BC, Canada},
    series = {NIPS '20},
    doi = {https://doi.org/10.48550/arXiv.2005.11401},
    keywords = {}
}
@INPROCEEDINGS{10447898,
  author={Yuan, Yi and Liu, Haohe and Liu, Xubo and Huang, Qiushi and Plumbley, Mark D. and Wang, Wenwu},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Retrieval-Augmented Text-to-Audio Generation}, 
  year={2024},
  volume={},
  number={},
  pages={581-585},
  abstract={Despite recent progress in text-to-audio (TTA) generation, we show that the state-of-the-art models, such as AudioLDM, trained on datasets with an imbalanced class distribution, such as AudioCaps, are biased in their generation performance. Specifically, they excel in generating common audio classes while underperforming in the rare ones, thus degrading the overall generation performance. We refer to this problem as long-tailed text-to-audio generation. To address this issue, we propose a simple retrieval-augmented approach for TTA models. Specifically, given an input text prompt, we first leverage a Contrastive Language Audio Pretraining (CLAP) model to retrieve relevant text-audio pairs. The features of the retrieved audio-text data are then used as additional conditions to guide the learning of TTA models. We enhance AudioLDM with our proposed approach and denote the resulting augmented system as Re-AudioLDM. On the AudioCaps dataset, Re-AudioLDM achieves a state-of-the-art Frechet Audio Distance (FAD) of 1.37, outperforming the existing approaches by a large margin. Furthermore, we show that Re-AudioLDM can generate realistic audio for complex scenes, rare audio classes, and even unseen audio types, indicating its potential in TTA tasks.},
  keywords={Measurement;Tail;Signal processing;Data models;Acoustics;Task analysis;Speech processing;Audio generation;retrieval-information;diffusion model;deep learning;long tail problem},
  doi={10.1109/ICASSP48485.2024.10447898},
  ISSN={2379-190X},
  month={April},
}
@misc{izacard2021leveragingpassageretrievalgenerative,
      title={Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering}, 
      author={Gautier Izacard and Edouard Grave},
      year={2021},
      eprint={2007.01282},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2007.01282}, 
}
@misc{karpukhin2020densepassageretrievalopendomain,
      title={Dense Passage Retrieval for Open-Domain Question Answering}, 
      author={Vladimir Karpukhin and Barlas Oğuz and Sewon Min and Patrick Lewis and Ledell Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},
      year={2020},
      eprint={2004.04906},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2004.04906}, 
}
@inproceedings{huang-etal-2022-concrete,
    title = {CONCRETE: Improving Cross-lingual Fact-checking with Cross-lingual Retrieval},
    author = {Huang, Kung-Hsiang  and
      Zhai, ChengXiang  and
      Ji, Heng},
    editor = {Calzolari, Nicoletta  and
      Huang, Chu-Ren  and
      Kim, Hansaem  and
      Pustejovsky, James  and
      Wanner, Leo  and
      Choi, Key-Sun  and
      Ryu, Pum-Mo  and
      Chen, Hsin-Hsi  and
      Donatelli, Lucia  and
      Ji, Heng  and
      Kurohashi, Sadao  and
      Paggio, Patrizia  and
      Xue, Nianwen  and
      Kim, Seokhwan  and
      Hahm, Younggyun  and
      He, Zhong  and
      Lee, Tony Kyungil  and
      Santus, Enrico  and
      Bond, Francis  and
      Na, Seung-Hoon},
    booktitle = {Proceedings of the 29th International Conference on Computational Linguistics},
    month = {oct},
    year = {2022},
    address = {Gyeongju, Republic of Korea},
    publisher = {International Committee on Computational Linguistics},
    url = {https://aclanthology.org/2022.coling-1.86/},
    pages = {1024--1035},
    abstract = {Fact-checking has gained increasing attention due to the widespread of falsified information. Most fact-checking approaches focus on claims made in English only due to the data scarcity issue in other languages. The lack of fact-checking datasets in low-resource languages calls for an effective cross-lingual transfer technique for fact-checking. Additionally, trustworthy information in different languages can be complementary and helpful in verifying facts. To this end, we present the first fact-checking framework augmented with cross-lingual retrieval that aggregates evidence retrieved from multiple languages through a cross-lingual retriever. Given the absence of cross-lingual information retrieval datasets with claim-like queries, we train the retriever with our proposed Cross-lingual Inverse Cloze Task (X-ICT), a self-supervised algorithm that creates training instances by translating the title of a passage. The goal for X-ICT is to learn cross-lingual retrieval in which the model learns to identify the passage corresponding to a given translated title. On the X-Fact dataset, our approach achieves 2.23{\%} absolute F1 improvement in the zero-shot cross-lingual setup over prior systems. The source code and data are publicly available at \url{https://github.com/khuangaf/CONCRETE}.}
}
@misc{liu2021kgbartknowledgegraphaugmentedbart,
      title={KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning}, 
      author={Ye Liu and Yao Wan and Lifang He and Hao Peng and Philip S. Yu},
      year={2021},
      eprint={2009.12677},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2009.12677}, 
}
@inproceedings{zhang-etal-2020-grounded,
    title = {Grounded Conversation Generation as Guided Traverses in Commonsense Knowledge Graphs},
    author = {Zhang, Houyu  and
      Liu, Zhenghao  and
      Xiong, Chenyan  and
      Liu, Zhiyuan},
    editor = {Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel},
    booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
    month = {jul},
    year = {2020},
    address = {Online},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2020.acl-main.184/},
    doi = {10.18653/v1/2020.acl-main.184},
    pages = {2031--2043},
    abstract = {Human conversations naturally evolve around related concepts and hop to distant concepts. This paper presents a new conversation generation model, ConceptFlow, which leverages commonsense knowledge graphs to explicitly model conversation flows. By grounding conversations to the concept space, ConceptFlow represents the potential conversation flow as traverses in the concept space along commonsense relations. The traverse is guided by graph attentions in the concept graph, moving towards more meaningful directions in the concept space, in order to generate more semantic and informative responses. Experiments on Reddit conversations demonstrate ConceptFlow`s effectiveness over previous knowledge-aware conversation models and GPT-2 based models while using 70{\%} fewer parameters, confirming the advantage of explicit modeling conversation structures. All source codes of this work are available at \url{https://github.com/thunlp/ConceptFlow}.}
}
@article{Gao2022RetrievalAugmentedMK,
  title={Retrieval-Augmented Multilingual Keyphrase Generation with Retriever-Generator Iterative Training},
  author={Yifan Gao and Qingyu Yin and Zheng Li and Rui Meng and Tong Zhao and Bing Yin and Irwin King and Michael R. Lyu},
  journal={ArXiv},
  year={2022},
  volume={abs/2205.10471},
  url={https://api.semanticscholar.org/CorpusID:248986542}
}
@misc{sun2024thinkongraphdeepresponsiblereasoning,
      title={Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph}, 
      author={Jiashuo Sun and Chengjin Xu and Lumingyuan Tang and Saizhuo Wang and Chen Lin and Yeyun Gong and Lionel M. Ni and Heung-Yeung Shum and Jian Guo},
      year={2024},
      eprint={2307.07697},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.07697}, 
}